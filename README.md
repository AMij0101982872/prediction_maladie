# ğŸ§  Projet de Machine Learning â€“ PrÃ©diction de Maladie

## ğŸ“Œ Objectif du projet

Ce projet vise Ã  **prÃ©dire la prÃ©sence dâ€™une maladie (classe 1)** chez des patients Ã  partir de donnÃ©es cliniques. Le principal dÃ©fi est le **dÃ©sÃ©quilibre des classes**, la classe malade Ã©tant minoritaire.

Lâ€™objectif mÃ©tier prioritaire est donc :
ğŸ‘‰ **Maximiser le rappel et le F1-score de la classe 1**, afin de dÃ©tecter le plus de patients malades possible.

## âš™ï¸ PrÃ©traitement des donnÃ©es

Les donnÃ©es contiennent des **variables numÃ©riques et catÃ©gorielles**.

### ğŸ”¹ Ã‰tapes de preprocessing

* Imputation des valeurs manquantes

  * NumÃ©riques : moyenne
  * CatÃ©gorielles : modalitÃ© la plus frÃ©quente
* Encodage des variables catÃ©gorielles (OneHotEncoder)
* Standardisation des variables numÃ©riques (StandardScaler)

Ces Ã©tapes sont regroupÃ©es dans un **ColumnTransformer**, intÃ©grÃ© directement dans les pipelines.

---

##  ModÃ¨les testÃ©s

### 1ï¸ Logistic Regression â€“ Baseline

* Pipeline : Preprocessing + LogisticRegression
* Sans gestion du dÃ©sÃ©quilibre

ğŸ“‰ RÃ©sultat :

* Bonne performance sur la classe 0
* Mauvais rappel sur la classe 1

---

### 2ï¸ Logistic Regression avec ACP (PCA 95%)

* RÃ©duction de dimension aprÃ¨s preprocessing

ğŸ“‰ RÃ©sultat :

* Baisse globale des performances
* Forte dÃ©gradation du rappel de la classe 1

 **Conclusion** : lâ€™ACP a supprimÃ© des variables discriminantes importantes.

---

### 3ï¸ Logistic Regression Ã©quilibrÃ©e + GridSearchCV âœ…

* `class_weight="balanced"`
* Optimisation des hyperparamÃ¨tres via GridSearchCV

ğŸ“ˆ RÃ©sultat :

* AmÃ©lioration significative du rappel de la classe 1
* Meilleur compromis biais / variance
* ModÃ¨le interprÃ©table

---

### 4ï¸ KNN + SMOTE + PCA + GridSearchCV

* Pipeline Imbalanced-learn (`ImbPipeline`)
* Sur-Ã©chantillonnage avec SMOTE
* PCA pour rÃ©duction de dimension
* Optimisation de `n_neighbors`

ğŸ“ˆ RÃ©sultat :

* Bon rappel de la classe 1
* Performance globale correcte
* ModÃ¨le sensible au bruit et moins interprÃ©table

---

## ğŸ“Š Comparaison des modÃ¨les Logistic Regression

| ModÃ¨le                  | Accuracy | Rappel classe 1 | F1 classe 1 | Commentaire                  |
| ----------------------- | -------- | --------------- | ----------- | ---------------------------- |
| Baseline                | â‰ˆ 0.71   | â‰ˆ 0.36          | â‰ˆ 0.46      | DÃ©tecte mal les malades      |
| Avec PCA (95%)          | â‰ˆ 0.67   | â‰ˆ 0.26          | â‰ˆ 0.36      | Perte dâ€™information critique |
| Balanced + GridSearchCV | â‰ˆ 0.70   | â‰ˆ 0.64          | â‰ˆ 0.60      | â­ Meilleur compromis         |

---

##  ModÃ¨le final retenu

 **Logistic Regression avec `class_weight='balanced'` et hyperparamÃ¨tres optimisÃ©s**

### Pourquoi ce choix ?

* TrÃ¨s bon rappel sur la classe malade
* F1-score satisfaisant
* Robuste sur validation croisÃ©e
* InterprÃ©table (important en contexte mÃ©dical)

---

## ğŸš€ EntraÃ®nement final

Le modÃ¨le final est **entraÃ®nÃ© sur lâ€™ensemble des donnÃ©es disponibles** afin de maximiser lâ€™apprentissage avant dÃ©ploiement.

```python
best_model.fit(X, y)
```

---

##  AmÃ©liorations possibles

* Tester XGBoost / LightGBM avec gestion du dÃ©sÃ©quilibre
* Ajuster le seuil de dÃ©cision (0.5 â†’ 0.3)
* Analyse SHAP pour interprÃ©tabilitÃ© avancÃ©e
* Validation externe sur nouvelles donnÃ©es

---

## ğŸ› ï¸ Technologies utilisÃ©es

* Python
* scikit-learn
* imbalanced-learn
* pandas / numpy
* matplotlib / seaborn

---

## ğŸ‘¤ Auteur

**Mobio Ivan Junior Ake**
Machine Learning & Data Science



 *Projet prÃªt pour GitHub /
 https://predictionmaladie-chd.streamlit.app/
